\documentclass[12pt]{article}
\usepackage{ctex}
\usepackage[english]{babel}
\usepackage{blindtext}
\usepackage{nameref}
\usepackage{fancyhdr}
\usepackage{color,amsmath,amssymb,amsthm,physics}
\usepackage{graphicx,float}
\usepackage{physics}
\usepackage{pgfplots}
\usepackage[a4paper, total={7in, 9in}]{geometry}
\usepackage{multicol}
\usepackage{framed}
\usepackage{xcolor}

\graphicspath{ {../images/} }

\definecolor{shadecolor}{RGB}{220,220,220}

\pagestyle{fancy}
\fancyhf{}
\fancyhf[HL]{A short course on Limit}
\fancyhf[HR]{\rightmark}
\fancyhf[CF]{\thepage}
\fancyhf[FL]{\copyright Mok Owen 2024}

\newcommand{\innerprod}[2]{\langle{#1},{#2}\rangle}
\newcommand{\id}{\mathtt{id}}
\newcommand{\cis}[1]{\mathrm{cis}({#1})}

\newtheorem{definition}{Definition}[section]
\newtheorem*{theorem}{Theorem}
\newtheorem*{corollary}{Corollary}
\newtheorem*{lemma}{Lemma}
\newtheorem*{proposition}{Proposition}
\newtheorem*{remark}{Remark}
\newtheorem*{claim}{Claim}
\newtheorem*{example}{Example}
\newtheorem*{axiom}{Axiom}

\newtheorem{exercise}{Essential Practice}[section]
\newenvironment{solution}{\begin{snugshade*} \underline{\textbf{Solution.}} \par}{\hfill \textit{\dots end of solution} \end{snugshade*}}
\renewenvironment{proof}[1][Proof]{\begin{snugshade*} \underline{\textit{{#1}.}}\\}{\hfill \qedsymbol \end{snugshade*}}

\begin{document}
    \begin{abstract}
        To understand the concept of calculus well, it is indeed not a compulsory to learn the theory of limit. However, the consolidation and confirmation of the knowledge in both differentiation and integration depends on limit application heavily, so it worths learning the sense behind. We all know that Newton found caculus a.k.a. dynamic flow without limit thoery, but the mystery of calculus makes sense until the explanation by limit.
    \end{abstract}

    \section{Sense of approximation}

    What comes first is the sense of approximation. We need to approximate \textit{almost everything} in the real world, such as taking values on a ruler, the water level in a beaker, making a 3-point shot in a basketball game. Not everything can be controlled exactly, even that writing a figure or an alphabet can be so different in every trial. That means we are living in a world of approximation.

    Now, imagine if we have two slices of thin bread and a thin slice of cheese, we placed one thin bread on the plate first, then the thin slice of cheese on top of the placed bread, then the other thin bread on top of the placed cheese. For instance, we have no information about the coordinates of the objects. How should we describe the places of the slice of \textbf{thin cheese}?

    It is natural to answer `between the slices of bread'. The step to understand limit is to think more about the case when the slices are thin enough to say `of zero length'. In such cases, are the places of cheese and bread `the same'?

    It turns out that they are nearly \textit{the same} place.

    \section{Limit definition}

    Therefore, we ought to write down the meaning of `close enough' in a logical way. Define a function to represent distance:

    \begin{definition}[Absolute value function]
        The function $|\cdot|:\mathbb{R}\to\mathbb{R}_{\geq 0}$ is defined by \[x\mapsto \sqrt{x^2}\] or in separation form \[x\mapsto \begin{cases}
            x&,\textrm{if }x\geq 0,\\
            -x&,\textrm{if }x< 0
        \end{cases}\]
    \end{definition}

    \begin{example}
        \begin{enumerate}
            \item $|1|=|-1|=1$.
            \item $|2|=|-2|=2$.
            \item $|3|=|-3|=3$.
        \end{enumerate}
    \end{example}

    In order to facilitate the usage of absolute value function, we ought to develop some properties on its computation.

    \begin{proposition}
        The absolute value function is positive-definite: \begin{enumerate}
            \item  For every $x\in\mathbb{R}, |x|\geq 0$; 
            \item $|x|=0$ if and only if $x=0$.
        \end{enumerate}
    \end{proposition}

    \begin{proof}
        Both statement are trivially following from the definition of absolute value function. The checking will be left as an intuition for students.
    \end{proof}

    \begin{proposition}
        Given $x\in\mathbb{R}$, \[|x|\geq x.\]
    \end{proposition}

    \begin{proof}
        If $x\geq 0$, then $|x|=x$; if $x<0$, then $|x|>0>x$.
    \end{proof}

    \begin{proposition}
        Given $x,y\in\mathbb{R}$, \[|xy|=|x||y|.\]
    \end{proposition}

    \begin{proof}
        It is easy to check all cases for it, i.e. $(x,y)\in\{(+,+),(+,-),(-,+),(-,-)\}$. I will put the analytic way of proof to facilitate understanding.

        Notice $|x|=\sqrt{x^2}$, therefore $|xy|=\sqrt{(xy)^2}=\sqrt{x^2}\sqrt{y^2}=|x||y|$.
    \end{proof}

    \begin{proposition}
        Triangle inequality holds for absolute value function: For every real pair $x$ and $y$, \[|x+y|\leq |x|+|y|.\]
    \end{proposition}

    \begin{proof}
        Consider the definition of absolute value function that $|x|=\sqrt{x^2}$, we will pay attention to prove \[|x+y|^2\leq (|x|+|y|)^2\] instead of the one stated. The statement in the proposition follows from positivity of absolute value function.

        Notice that \begin{align*}
            (|x|+|y|)^2-|x+y|^2&=|x|^2+2|x||y|+|y|^2-x^2-2xy-y^2\\
            &=2(|x||y|-xy)\\
            &\geq 0
        \end{align*}

        Therefore, by rearrangement of terms, the proof is done.
    \end{proof}

    For the distance between any two numbers $x$ and $y$, where they are not necessary be distinct, can be defined as \[\mathrm{dist}(x,y)=|x-y|.\]

    In addition to the meaning of distance, we can observe the following property:

    \begin{proposition}
        The distance function is symmetric: \[\mathrm{dist}(x,y)=\mathrm{dist}(y,x).\]
    \end{proposition}

    \begin{proof}
        Due to $|-x|=|-1||x|=|x|$, we have \[|x-y|=|-(y-x)|=|y-x|.\]
        Hence, $\mathrm{dist}(x,y)=\mathrm{dist}(y,x)$.
    \end{proof}

    From this definition, we can now write the following:

    \begin{definition}[Formal definition of limit of a function]
        Suppose $f:\mathbb{R}\to\mathbb{R}$ be a function defined on real number domain, and not necessary be defined on $x=x_0$. Let $\varepsilon>0$ be an arbitrary number. If for such $\varepsilon$ there always exists a number $\delta>0$ depends on it, write $\delta:=\delta(\varepsilon)$ as a function depends on $\varepsilon$, such that whenever $0<|x-x_0|<\delta$, there is always a number $L$ such that $|f(x)-L|<\varepsilon$, then we will say $L$ to be the \textbf{limit of $f$ at $x_0$}, written as \[\lim_{x\to x_0}f(x)=L.\]
    \end{definition}

    For a limit, we can consider without knowing the value of the function at the limit point. It is because every discussion of limit is the discussion of approximated value. Let us analyze the writing in the definition.\begin{itemize}
        \item A function should be defined to discuss limit of a function, but \textit{not necessary} be defined on the point we want to have limit. The point is that approximation need no information about the actual value, as we did for looking at a ruler, we could never say any words about the exact length. For who couldn't understand the meaning of it, let me ask a question: do you know the exact length of a pencil if it is measured by a centimetre-ruler?
        \item The number $\varepsilon$ is set to be arbitrary to keep the variation of boundary. This variable acts as an upper limit for the distance between the limit $L$ of $f$ at $x_0$.
        \item The number $\delta=\delta(\varepsilon)$ defines an upper bound for the distance between $x$ and $x_0$. The function-like presentation is to clarify that $\delta$ is dependent on $\varepsilon$.
    \end{itemize}

    The question is whether the number $L$ unique. We will take care of it in short and dive into the application and theorems of limit.

    \begin{proof}[Proof of the uniqueness of limit of a function]
        Suppose the limit situation holds for two numbers $L$ and $L'$: \[\forall \varepsilon > 0, \exists \delta > 0, (0<|x-x_0|<\delta)\implies (|f(x)-L|<\varepsilon)\] and \[\forall \varepsilon' > 0, \exists \delta' > 0, (0<|x-x_0|<\delta')\implies (|f(x)-L'|<\varepsilon')\]
        Pick for an arbitrary $\varepsilon''>0$, then we may choose $\delta'':=\min\{\delta,\delta'\}$ such that \[(0<|x-x_0|<\delta'')\implies (|f(x)-L|<\varepsilon''), (|f(x)-L'|<\varepsilon'')\]
        Then \begin{align*}
            |L-L'|&=|L-f(x)+f(x)-L'|\\
            &\leq |L-f(x)|+|f(x)-L'|\\
            &<2\varepsilon''
        \end{align*}
        Since $\varepsilon$ is arbitrarily chosen, it turns out only $L=L'$ makes sense in any situation.
    \end{proof}

    \begin{remark}
        Since limit of a function is unique, we will call $\lim_{x\to x_0}f(x)$ to be \textbf{the limit of $f$ at $x_0$}.
    \end{remark}

    \section{Evaluation of simple limits}

    We will see the techniques of evaluating a limit in this section, provided with some useful theorems.

    \begin{theorem}
        If $f(x)$ is well-defined at $x_0$, and continuous near $x_0$, then \[\lim_{x\to x_0}f(x)=f(x_0).\]
    \end{theorem}

    \begin{example}
        The following examples shows continuous function's limit.
        \begin{enumerate}
            \item $\lim_{x\to 0}x=0$, $\lim_{x\to 1}x=1$, $\lim_{x\to 2}x=2$, $\dots$;
            \item $\lim_{x\to 0}x^2=0$, $\lim_{x\to 1}x^2=1$, $\lim_{x\to 2}x^2=4$, $\dots$.
        \end{enumerate}
    \end{example}

    In order to manage polynomial functions, we have some rules of arithmetic of limit.

    \begin{theorem}[Arithmetic on limit]
        Let $f,g$ be functions having limit at $x_0$. Then\begin{enumerate}
            \item $\displaystyle\lim_{x\to x_0}(f\pm g)=\lim_{x\to x_0}f \pm \lim_{x\to x_0}g$;
            \item $\displaystyle\lim_{x\to x_0}fg = (\lim_{x\to x_0}f)(\lim_{x\to x_0}g)$;
            \item If $\displaystyle\lim_{x\to x_0}g(x)\neq 0$, then $\displaystyle\lim_{x\to x_0}\frac{f}{g}=\frac{\lim_{x\to x_0}f}{\lim_{x\to x_0}g}$.
        \end{enumerate}
    \end{theorem}

    \begin{proof}
        The proofs for the three statement will be done by the definition of limit. Let $\varepsilon>0$ be an arbitrary number, with $\delta:=\delta(\varepsilon)$ be chosen according to that in definition, such that $0<|x-x_0|<\delta$ implies both $|f(x)-F|<\varepsilon$ and $|g(x)-G|<\varepsilon$. It is clear that $\displaystyle\lim_{x\to x_0}f(x)=F$ and $\displaystyle\lim_{x\to x_0}g(x)=G$ in this construction. Each deduction part will be given as follows.
        \begin{enumerate}
            \item We need to show $\big|[f(x)\pm g(x)]-[F\pm G]\big|<\varepsilon$:\begin{align*}
                \big|[f(x)\pm g(x)]-[F\pm G]\big|&=\big|[f(x)-F]\pm[g(x)-G]\big|\\
                &\leq |f(x)-F|+|g(x)-G|\\
                &<2\varepsilon
            \end{align*}
            Since $\varepsilon>0$ is arbitrarily chosen, the result follows.
            \item We need to show $|f(x)g(x)-FG|<\varepsilon$:\begin{align*}
                |f(x)g(x)-FG|&=|f(x)g(x)-Fg(x)+Fg(x)-FG|\\
                &\leq |f(x)g(x)-Fg(x)|+|Fg(x)-FG|\\
                &=|g(x)||f(x)-F|+|F||g(x)-G|
            \end{align*}
            The odd part in the deduction is the value of $|g(x)|$, but remember the properties of absolute value function leads us to the conclusion \[|g(x)-G|<\varepsilon \implies G-\varepsilon<g(x)<G+\varepsilon.\]
            Then the finiteness of $G$ and $\varepsilon$ tells there exists another finite number $G_0$ such that \[|g(x)|<G_0\] and that \begin{align*}
                |f(x)g(x)-FG|&\leq |g(x)||f(x)-F|+|F||g(x)-G|\\
                &<(G_0+|F|)\varepsilon
            \end{align*}
            Since $\varepsilon>0$ is arbitrarily chosen, the result follows.
            \item Similar to previous proofs, we aim to show that $|\frac{f(x)}{g(x)}-\frac{F}{G}|<\varepsilon$:\begin{align*}
                |\frac{f(x)}{g(x)}-\frac{F}{G}|&=|\frac{Gf(x)-Fg(x)}{Gg(x)}|\\
                &=|\frac{Gf(x)-FG+FG-Fg(x)}{Gg(x)}|\\
                &\leq \frac{1}{|G||g(x)|}(|G||f(x)-F|+|F||G-g(x)|)\\
                &<\frac{|G|+|F|}{|G||g(x)|}\varepsilon
            \end{align*}
            For this time, the tricky part is to bound the value of $\frac{1}{|g(x)|}$. In fact, from previous proof we know that \[G-\varepsilon<g(x)<G+\varepsilon \implies \frac{1}{G+\varepsilon}<\frac{1}{g(x)}<\frac{1}{G-\varepsilon}\] which, by the arbitrariness of $\varepsilon$, there is always a $g_0>0$ such that $\frac{1}{|g(x)|}<g_0$. The result then follows from writing \[|\frac{f(x)}{g(x)}-\frac{F}{G}|<\frac{|G|+|F|}{|G|}g_0\varepsilon.\]
        \end{enumerate}
    \end{proof}

    We will examine the rules by checking some basic examples using polynomial functions.

    \begin{example}
        Check the following limits:\begin{enumerate}
            \item $\displaystyle\lim_{x\to 0}(x^2+2x-1)=0^2+0-1=-1$;
            \item $\displaystyle\lim_{x\to 3}[4(x^2-2)(x+3)]=4(3^2-2)(3+3)=168$;
            \item $\displaystyle\lim_{x\to -1}\frac{x-1}{x-2}=\frac{-1-1}{-1-2}=\frac{2}{3}$.
        \end{enumerate}
    \end{example}

    \begin{exercise}
        Compute the following limits with the help of rules provided:\begin{enumerate}
            \item $\displaystyle\lim_{x\to 1}(3x^2-2x+4)$;
            \item $\displaystyle\lim_{x\to 2}[x(x+1)(x+2)]$;
            \item $\displaystyle\lim_{x\to 0}\frac{x+2}{(x+1)^2}$.
        \end{enumerate}
    \end{exercise}

    More than direct substitution, one may bump into the situation of $\frac{0}{0}$, which is undefined in usual sense. For if we are doing limits, we know that $x\to x_0$ means $x$ is approaching $x_0$, but they can never be equal. We hence introduce a concept of identification on limit results.

    \begin{proposition}
        Let $f,g:\mathbb{R}\to\mathbb{R}$ be functions. If $f(x)=(x-a)g(x)$, and both $\lim_{x\to a} f(x)$ and $\lim_{x\to a}g(x)$ exists, then \[\lim_{x\to a}\frac{f(x)}{x-a}=\lim_{x\to a}g(x).\]
    \end{proposition}

    \begin{proof}
        By definition of limit, when $0<|x-a|<\delta$, \[|\frac{f(x)}{x-a}-L|=|\frac{(x-a)g(x)}{x-a}-L|=|g(x)-L|.\] Therefore, the result follows.
    \end{proof}

    \begin{corollary}
        Let $f,g,p,q:\mathbb{R}\to\mathbb{R}$ be functions. If $f(x)=(x-a)p(x)$ and $g(x)=(x-a)q(x)$, and all limit exists with $q(x)\neq 0$, then \[\lim_{x\to a}\frac{f(x)}{g(x)}=\lim_{x\to a}\frac{p(x)}{q(x)}.\]
    \end{corollary}

    \begin{remark}
        The above proposition can be named as the \textbf{removable discontinuity}. It's application can be seen in extending functions with finite discontinuities to continuous functions.
    \end{remark}

    Here are some applications of the properties when evaluating limits.

    \begin{example}
        Check the following limit:
        \begin{enumerate}
            \item $\displaystyle \lim_{x\to 0}\frac{x(x+1)}{x}=\lim_{x\to 0}(x+1)=1$;
            \item $\displaystyle \lim_{x\to 1}\frac{x(x-1)}{(x-1)(x-2)}=\lim_{x\to 1}\frac{x}{x-2}=-1$;
            \item $\displaystyle \lim_{x\to -1}\frac{x^2-3x-4}{x^2+3x+2}=\lim_{x\to -1}\frac{(x+1)(x-4)}{(x+1)(x+2)}=\lim_{x\to -1}\frac{x-4}{x+2}=-5$;
        \end{enumerate}
    \end{example}

    \begin{exercise}
        Compute the following limit:
        \begin{enumerate}
            \item $\displaystyle \lim_{x\to -3}\frac{x(x+3)}{x+3}$;
            \item $\displaystyle \lim_{x\to 0}\frac{x(x-1)}{x(x-2)}$;
            \item $\displaystyle \lim_{x\to 1}\frac{x^2+3x-4}{x^2-2x+1}$.
        \end{enumerate}
    \end{exercise}

    \section{Limits to infinity}

    When the limit tends to a finite number, it is easy to show the convergence when discontinuities are removed. However, we have less idea on how it works when limit goes nowhere finite.
    
    We observe one divengence to extend the logic of limit. Consider the counting on integers increased from $1,2,3,\dots$ to nowhere terminate. If we let any integer $M$ as a virtual boundary of the counting, one could see $M+1$ can again be an integer such that $M+1>M$ and $M$ will no longer be an upper bound. This facilitate a sense of `unlimited' and we use the symbol $\infty$ to denote the meaning.

    \begin{definition}[Infinity]
        Define a symbol $\infty$ such that for any integer $N$, $N$ is always less than $\infty$.
    \end{definition}

    \begin{proposition}
        Any real number $x\in\mathbb{R}$ is less than $\infty$.
    \end{proposition}

    \begin{proof}
        For all $x\in \mathbb{R}$, there is always some integer $M$ such that \[M\leq x< M+1.\] Since $M+1\in\mathbb{N}$, it follows $x<M+1<\infty$.
    \end{proof}

    \begin{remark}
        In the proof, such $M$ is called the \textbf{integral part of $x$}, and we can define the \textbf{floor function} $\lfloor \cdot \rfloor:\mathbb{R}\to\mathbb{N}$ such that \[\lfloor x \rfloor = M.\] In addition, the \textbf{fractional part}, follows the meaning in mixed fraction ($a\frac{b}{c}$), can be defined by $[\cdot]:\mathbb{R}\to (0,1)$ as \[[x]=x-\lfloor x \rfloor,\] and the \textbf{ceiling function} $\lceil \cdot \rceil:\mathbb{R}\to\mathbb{N}$ to be \[\lceil x \rceil=\lfloor x \rfloor + 1.\]
    \end{remark}

    Observe the function $f(x):=\frac{1}{x}$, we may check that \begin{enumerate}
        \item $\displaystyle \lim_{x\to 0^+}f(x)=\infty$;
        \item $\displaystyle \lim_{x\to 0^-}f(x)=-\infty$;
        \item $\displaystyle \lim_{x\to \infty}f(x)=0$.
    \end{enumerate}

    \begin{proof}
        For each $x\in\mathbb{R}$, there is always an integer $N$ such that $0<\frac{1}{N}<x$.
    \end{proof}

    The above results provides a foundation on defining a bounded version of real numbers, call it the \textbf{extended real number set}.

    \begin{definition}[Extended real number set]
        The set $\overline{\mathbb{R}}:=\mathbb{R}\cup\{-\infty,\infty\}$ is called an \textbf{extended real number set}. We usually simply write $\mathbb{R}$ to mean the extended one.
    \end{definition}

    Such definition transform the usage of $\infty$ from a simple concept to a `number', though it is not rigorous to say it is a number, but it founds the properties of $\mathbb{R}$ useful.

    \begin{theorem}
        For any finite real numbers $a>0,b<0$, the following holds:\begin{enumerate}
            \item $a+\infty=b+\infty=\infty+a=\infty+b=\infty$;
            \item $a-\infty=b-\infty=-\infty$;
            \item $a\infty=\infty$;
            \item $b\infty=-\infty$;
            \item $a/\infty=b/\infty=0$.
        \end{enumerate}
    \end{theorem}

    \begin{example}
        The following results obey the rules defined. For $a>0,b$ be finite real numbers,
        \begin{enumerate}
            \item $\displaystyle\lim_{x\to \infty}(ax+b)=\infty$;
            \item $\displaystyle\lim_{x\to -\infty}(ax+b)=-\infty$;
            \item $\displaystyle\lim_{x\to \infty}(-ax+b)=-\infty$;
            \item $\displaystyle\lim_{x\to -\infty}(-ax+b)=\infty$;
            \item $\displaystyle\lim_{x\to \infty}(a/x+b)=b$;
            \item $\displaystyle\lim_{x\to -\infty}(a/x+b)=b$.
        \end{enumerate}
    \end{example}

    \begin{exercise}
        Prove the results stated in the example. For application result, try to perform calculations with limit rules; for verification, show the limit is true using formal definition.
    \end{exercise}

    And if we take care of some higher degree cases, one would observe \[\lim_{x\to \infty}x^n = \infty,\] and \[\lim_{x\to -\infty}x^n = \begin{cases}
        \infty, &n\textrm{ is even,}\\
        -\infty, &n\textrm{ is odd.}
    \end{cases}\]

    Combining with the arithmetic rules of limit, we can now check the results of polynomials.

    \begin{exercise}
        Compute the following limits:\begin{enumerate}
            \item $\displaystyle\lim_{x\to \infty}(3x+2)$;
            \item $\displaystyle\lim_{x\to -\infty}(4x^2+3)$;
            \item $\displaystyle\lim_{x\to -\infty}(-4x+3)$;
            \item $\displaystyle\lim_{x\to \infty}(a/x^2+b)$.
        \end{enumerate}
    \end{exercise}

    The discussion on determinate form is easy to handle, however, not the same picture for if it is the indeterminate form. We identify the following forms as indeterminate forms: \[\frac{0}{0}, \frac{\infty}{\infty}, 0\cdot \infty, 0^0, 0^\infty, \infty^0, 1^\infty\]

    Since the limit value of the above forms are very unstable, according to their defining functions, resulting in many variations. However, one of the above forms is quite interesting to discuss with, was the form $1^\infty$.
    \section{Limits with special functions}

    In dealing with the form $1^\infty$, we obtain a popular function, called \textbf{the exponential function} $\exp$. To find its importance in mathematics, we shall take account into its origination.

    Let us start by investigating the natural growth function, i.e. the compound interest progression, stated as \[f_n(x,t):=A_0(1+\frac{x}{n})^{nt}.\] It is noticeable that $f_n(0,t)=f_n(x,0)=A_0$, as $A_0$ is a conditional constant. Let us set $A_0=1$ to simplify the condition first. We are interested in the convergence when $n\to \infty$: The situation for `naturality', random growth occurrence with a statistical mean growth.

    We first claim that the sequence $f_n$ is an increasing sequence. We shall further divide this into different cases.
    
    \begin{claim}
        $f_n(1,1)$ is an increasing sequence according to $n$.
    \end{claim}

    \begin{proof}
        Consider the difference between $f_n(1,1)$ and $f_{n+1}(1,1)$.
        \begin{align*}
            f_{n+1}(1,1)-f_n(1,1)&=(1+\frac{1}{n+1})^{n+1}-(1+\frac{1}{n})^n.
        \end{align*}
        
        Note that \begin{align*}
            C_k^{n+1}(\frac{1}{n+1})^k&=\frac{(n+1)!}{k!(n+1-k)!(n+1)^k}\\
            &=\frac{n^k}{(n+1-k)(n+1)^{k-1}}C_k^n\\
            &\geq C_k^n(\frac{1}{n})^k
        \end{align*}

        Therefore, \[(1+\frac{1}{n+1})^{n+1}-(1+\frac{1}{n})^n\geq 0,\] and \[f_{n+1}(1,1)\geq f_n(1,1)\,\forall n\in\mathbb{N}.\]
    \end{proof}

    \begin{claim}
        $f_{n+1}(x,1)\geq f_n(x,1)$; $f_n(x,t)=(f_n(x,1))^t$; and thus $f_{n+1}(x,t)\geq f_n(x,t)$.
    \end{claim}

    \begin{proof}
        Similar to previous claim, note that \begin{align*}
            C_k^{n+1}(\frac{x}{n+1})^k&=\frac{(n+1)!x^k}{k!(n+1-k)!(n+1)^k}\\
            &=\frac{n^k x^k}{(n+1-k)(n+1)^{k-1}}C_k^n\\
            &\geq C_k^n(\frac{x}{n})^k
        \end{align*}

        Also, \begin{align*}
            f_n(x,t)&=(1+\frac{x}{n})^{nt}\\
            &=[(1+\frac{x}{n})^n]^t\\
            &=(f_n(x,1))^t
        \end{align*}

        Therefore, \begin{align*}
            f_{n+1}(x,t)&=[f_{n+1}(x,1)]^t\\
            &\geq [f_n(x,1)]^t\\
            &=f_n(x,t)
        \end{align*}
    \end{proof}

    The second claim to build the limit is the boundedness of the sequence.

    \begin{claim}
        $f_n(1,1)$ is bounded above, so does $f_n(x,t)$.
    \end{claim}

    \begin{proof}
        Consider the formula \begin{align*}
            (1+\frac{1}{n})^n&=\sum_{k=0}^{n}C_k^n(\frac{1}{n})^k\\
            &\leq \sum_{k=0}^{n}\frac{1}{k!}\\
            &\leq \sum_{k=0}^{n}\frac{1}{2^{k-1}}\\
            &<4
        \end{align*}

        Next, to take care of $f_n(x,t)$, we need to show that $\exists K>0$ such that $f_n(x,1)\leq Kf_n(1,1)$ for all $n\in\mathbb{N}$.\begin{align*}
            f_n(x,1)&\leq \sum_{k=0}^{n}\frac{x^k}{k!}
        \end{align*} 
        For if $n$ is large enough such that $n>\lceil x\rceil$, we can write \begin{align*}
            f_n(x,1)&\leq \sum_{k=0}^{\lfloor x \rfloor}\frac{x^k}{k!}+\sum_{k=\lceil x\rceil}^{n}\frac{x^k}{k!}\\
            &\leq \sum_{k=0}^{\lfloor x \rfloor}\frac{x^k}{k!}+x^{\lceil x \rceil}\sum_{k=\lceil x\rceil}^{n}\frac{x^k}{k!}\\
        \end{align*}
    \end{proof}
\end{document}